{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e85f7e2",
   "metadata": {},
   "source": [
    "# RAG Chatbot Testing Without Gradio - Multi-Document Knowledge Base\n",
    "\n",
    "This notebook allows you to test the RAG (Retrieval-Augmented Generation) functionality without the Gradio interface. \n",
    "\n",
    "## üîó Unified Multi-Document RAG System\n",
    "\n",
    "This implementation creates a **unified knowledge base** that combines **ALL PDF files** in the directory into a single searchable database. Key features:\n",
    "\n",
    "- **üìö Multi-Document Reference:** Questions can draw information from any or all documents simultaneously\n",
    "- **üîç Cross-Document Intelligence:** Find connections and patterns across your entire document collection  \n",
    "- **üéØ Source Attribution:** See exactly which documents contributed to each answer\n",
    "- **üí° Comprehensive Answers:** Get insights that span multiple documents for richer responses\n",
    "\n",
    "## üìã Example Input and Output\n",
    "\n",
    "### Input Setup:\n",
    "```\n",
    "./sample_pdfs/\n",
    "‚îú‚îÄ‚îÄ harry_potter_book1.pdf\n",
    "‚îú‚îÄ‚îÄ harry_potter_book2.pdf\n",
    "```\n",
    "\n",
    "### Example Questions and Answers:\n",
    "\n",
    "Question: \"Which house was Harry assigned to?\"\n",
    "\n",
    "Output:\n",
    "```\n",
    "üí¨ Answer: Harry Potter was assigned to Gryffindor house at Hogwarts School of \n",
    "Witchcraft and Wizardry. The Sorting Hat placed him in Gryffindor after \n",
    "considering his qualities and characteristics.\n",
    "\n",
    "üìñ Referenced documents: harry_potter_book1.pdf\n",
    "üìä Used 2 chunks from 1 documents\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68560a5b",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "**Prerequisites:** Install Ollama from [https://ollama.com/](https://ollama.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c62b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# Import RAG functions from separate module\n",
    "from langchain.chains import RetrievalQA\n",
    "from rag_functions import document_loader, text_splitter, vector_database, get_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b7538a",
   "metadata": {},
   "source": [
    "## Check Ollama status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527815b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ollama is running!\n",
      "üì¶ Available models: ['llama2:latest']\n",
      "‚úÖ llama2 model is ready!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def check_ollama_status() -> bool:\n",
    "    \"\"\"\n",
    "    Check if Ollama service is running and what models are available.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if Ollama is running and llama2 model is available, False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Check if Ollama service is running\n",
    "        response = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            models = response.json().get('models', [])\n",
    "            print(\"‚úÖ Ollama is running!\")\n",
    "            print(f\"üì¶ Available models: {[m['name'] for m in models]}\")\n",
    "            \n",
    "            # Check if llama2 is available\n",
    "            llama_models = [m for m in models if 'llama2' in m['name']]\n",
    "            if llama_models:\n",
    "                print(\"‚úÖ llama2 model is ready!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  llama2 model not found. Run: ollama pull llama2\")\n",
    "                return False\n",
    "        else:\n",
    "            print(\"‚ùå Ollama API not responding\")\n",
    "            return False\n",
    "    except requests.exceptions.RequestException:\n",
    "        print(\"‚ùå Ollama is not running. Visit https://ollama.com/ for installation instructions.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking Ollama: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Check Ollama status\n",
    "ollama_ready = check_ollama_status()\n",
    "\n",
    "if not ollama_ready:\n",
    "    print(\"\\nüîß Setup required:\")\n",
    "    print(\"1. Install Ollama: https://ollama.com/\")\n",
    "    print(\"2. Start Ollama service\")\n",
    "    print(\"3. Download model: ollama pull llama2\")\n",
    "    print(\"4. Re-run this cell to verify\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef768c6",
   "metadata": {},
   "source": [
    "## Set Directory Path\n",
    "\n",
    "Define the directory path where your PDF files are located. Create a sample directory if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8194d14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF directory: /Users/tirthshah/git_personal/qa-bot-with-rag/sample_pdfs\n",
      "Directory exists: True\n"
     ]
    }
   ],
   "source": [
    "# Set the directory path for PDF files\n",
    "pdf_directory: Path = Path(\"./sample_pdfs\")\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "pdf_directory.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"PDF directory: {pdf_directory.absolute()}\")\n",
    "print(f\"Directory exists: {pdf_directory.exists()}\")\n",
    "\n",
    "# You can also use an absolute path to an existing directory\n",
    "# pdf_directory = Path(\"/path/to/your/pdf/files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631aec92",
   "metadata": {},
   "source": [
    "## Process All PDF Files and Create Combined Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a379207f",
   "metadata": {},
   "source": [
    "Scan the directory and list all available PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d39819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDF files:\n",
      "1. chamber_of_secrets.pdf (33.9 KB)\n",
      "2. philosophers_stone.pdf (27.8 KB)\n",
      "\n",
      "‚úÖ Ready to process 2 files\n"
     ]
    }
   ],
   "source": [
    "# List all PDF files in the directory\n",
    "pdf_files = list(pdf_directory.glob(\"*.pdf\"))\n",
    "\n",
    "print(f\"Found {len(pdf_files)} PDF files:\")\n",
    "for i, file_path in enumerate(pdf_files, 1):\n",
    "    file_size = file_path.stat().st_size / 1024  # Size in KB\n",
    "    print(f\"{i}. {file_path.name} ({file_size:.1f} KB)\")\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"\\n‚ö†Ô∏è  No PDF files found!\")\n",
    "    print(f\"Please add some PDF files to: {pdf_directory.absolute()}\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Ready to process {len(pdf_files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f38d4",
   "metadata": {},
   "source": [
    "Process all PDF files and combine into a single knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b32aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2 PDF files for combined knowledge base...\n",
      "======================================================================\n",
      "\n",
      "üìÅ Loading file 1/2: chamber_of_secrets.pdf\n",
      "----------------------------------------\n",
      "‚úÖ Document loaded successfully!\n",
      "üìÑ Number of pages: 2\n",
      "üìö Added 2 pages to combined knowledge base\n",
      "\n",
      "üìÅ Loading file 2/2: philosophers_stone.pdf\n",
      "----------------------------------------\n",
      "‚úÖ Document loaded successfully!\n",
      "üìÑ Number of pages: 1\n",
      "üìö Added 1 pages to combined knowledge base\n",
      "\n",
      "üîÑ Creating combined knowledge base from 3 total pages...\n",
      "------------------------------------------------------------\n",
      "üìä Created 9 chunks from all documents\n",
      "üìä Average chunk length: 804 characters\n",
      "\n",
      "üìã Chunk distribution by source:\n",
      "  - chamber_of_secrets.pdf: 5 chunks\n",
      "  - philosophers_stone.pdf: 4 chunks\n",
      "\n",
      "üóÑÔ∏è Creating unified vector database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tirthshah/miniforge3/envs/rag/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined knowledge base created successfully!\n",
      "üéØ Ready for RAG queries across all 2 documents\n"
     ]
    }
   ],
   "source": [
    "# Process all PDF files and combine into a single knowledge base\n",
    "all_documents = []\n",
    "processed_files = []\n",
    "\n",
    "if pdf_files:\n",
    "    print(f\"Processing {len(pdf_files)} PDF files for combined knowledge base...\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Load all documents\n",
    "    for i, file_path in enumerate(pdf_files, 1):\n",
    "        print(f\"\\nüìÅ Loading file {i}/{len(pdf_files)}: {file_path.name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            # Load document\n",
    "            documents = document_loader(file_path)\n",
    "            print(f\"‚úÖ Document loaded successfully!\")\n",
    "            print(f\"üìÑ Number of pages: {len(documents)}\")\n",
    "            \n",
    "            # Add source metadata to each document\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = file_path.name\n",
    "                doc.metadata['file_path'] = str(file_path)\n",
    "            \n",
    "            # Add to combined document list\n",
    "            all_documents.extend(documents)\n",
    "            \n",
    "            # Track processing info\n",
    "            processed_files.append({\n",
    "                'name': file_path.name,\n",
    "                'pages': len(documents),\n",
    "                'path': file_path\n",
    "            })\n",
    "            \n",
    "            print(f\"üìö Added {len(documents)} pages to combined knowledge base\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading document: {e}\")\n",
    "    \n",
    "    # Create combined chunks from all documents\n",
    "    if all_documents:\n",
    "        print(f\"\\nüîÑ Creating combined knowledge base from {len(all_documents)} total pages...\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Split all documents into chunks\n",
    "        all_chunks = text_splitter(all_documents)\n",
    "        \n",
    "        # Create unified vector database\n",
    "        print(f\"üìä Created {len(all_chunks)} chunks from all documents\")\n",
    "        print(f\"üìä Average chunk length: {sum(len(chunk.page_content) for chunk in all_chunks) / len(all_chunks):.0f} characters\")\n",
    "        \n",
    "        # Show source distribution\n",
    "        source_counts = {}\n",
    "        for chunk in all_chunks:\n",
    "            source = chunk.metadata.get('source_file', 'unknown')\n",
    "            source_counts[source] = source_counts.get(source, 0) + 1\n",
    "        \n",
    "        print(f\"\\nüìã Chunk distribution by source:\")\n",
    "        for source, count in source_counts.items():\n",
    "            print(f\"  - {source}: {count} chunks\")\n",
    "        \n",
    "        # Create the unified vector database\n",
    "        print(f\"\\nüóÑÔ∏è Creating unified vector database...\")\n",
    "        unified_vectordb = vector_database(all_chunks)\n",
    "        unified_retriever = unified_vectordb.as_retriever(\n",
    "            search_kwargs={'k': 2}\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Combined knowledge base created successfully!\")\n",
    "        print(f\"üéØ Ready for RAG queries across all {len(processed_files)} documents\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå No documents loaded successfully\")\n",
    "        unified_retriever = None\n",
    "        all_chunks = []\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No PDF files available to process\")\n",
    "    processed_files = []\n",
    "    unified_retriever = None\n",
    "    all_chunks = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c2e99b",
   "metadata": {},
   "source": [
    "## Test Unified RAG System\n",
    "\n",
    "Ask questions that can be answered using information from any document in the combined knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "230bf7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QA system\n",
    "llm = get_llm()\n",
    "\n",
    "unified_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=unified_retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e43f3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Question: Which house was Harry assigned to?\n",
      "------------------------------------------------------------\n",
      "üí¨ Answer: According to the passage, Harry Potter was assigned to Gryffindor House at Hogwarts School of Witchcraft and Wizardry.\n",
      "\n",
      "üìñ Referenced documents: philosophers_stone.pdf\n",
      "üìä Used 2 chunks from 1 documents\n",
      "\n",
      "============================================================\n",
      "\n",
      "‚ùì Question: What monster was hidden in the Chamber of Secrets?\n",
      "------------------------------------------------------------\n",
      "üí¨ Answer: According to the context provided, the monster hidden in the Chamber of Secrets is a Basilisk.\n",
      "\n",
      "üìñ Referenced documents: chamber_of_secrets.pdf\n",
      "üìä Used 2 chunks from 1 documents\n",
      "\n",
      "============================================================\n",
      "\n",
      "‚ùì Question: What monster was hidden in the Chamber of Secrets?\n",
      "------------------------------------------------------------\n",
      "üí¨ Answer: According to the context provided, the monster hidden in the Chamber of Secrets is a Basilisk.\n",
      "\n",
      "üìñ Referenced documents: chamber_of_secrets.pdf\n",
      "üìä Used 2 chunks from 1 documents\n",
      "\n",
      "============================================================\n",
      "\n",
      "‚ùì Question: Who is the main villain that Harry faces at the end of each of his first two years at Hogwarts?\n",
      "------------------------------------------------------------\n",
      "üí¨ Answer: The main villain that Harry faces at the end of each of his first two years at Hogwarts is Lord Voldemort.\n",
      "\n",
      "üìñ Referenced documents: chamber_of_secrets.pdf, philosophers_stone.pdf\n",
      "üìä Used 2 chunks from 2 documents\n",
      "\n",
      "============================================================\n",
      "\n",
      "‚ùì Question: Who is the main villain that Harry faces at the end of each of his first two years at Hogwarts?\n",
      "------------------------------------------------------------\n",
      "üí¨ Answer: The main villain that Harry faces at the end of each of his first two years at Hogwarts is Lord Voldemort.\n",
      "\n",
      "üìñ Referenced documents: chamber_of_secrets.pdf, philosophers_stone.pdf\n",
      "üìä Used 2 chunks from 2 documents\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test question - these can now reference any document in the knowledge base\n",
    "questions = [\n",
    "    \"Which house was Harry assigned to?\",\n",
    "    \"What monster was hidden in the Chamber of Secrets?\",\n",
    "    \"Who is the main villain that Harry faces at the end of each of his first two years at Hogwarts?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    response = unified_qa.invoke(question)\n",
    "    answer = response['result']\n",
    "    source_docs = response['source_documents']\n",
    "\n",
    "    print(f\"\\n‚ùì Question: {question}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    print(f\"üí¨ Answer: {answer}\")\n",
    "\n",
    "    # Show which documents were referenced\n",
    "    if source_docs:\n",
    "        referenced_files = set()\n",
    "        for doc in source_docs:\n",
    "            source_file = doc.metadata.get('source_file', 'unknown')\n",
    "            referenced_files.add(source_file)\n",
    "        \n",
    "        print(f\"\\nüìñ Referenced documents: {', '.join(referenced_files)}\")\n",
    "        print(f\"üìä Used {len(source_docs)} chunks from {len(referenced_files)} documents\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "            \n",
    "    else:\n",
    "        print(\"‚ùå No unified knowledge base available for testing\")\n",
    "        if not processed_files:\n",
    "            print(\"No files were processed successfully\")\n",
    "        if not unified_retriever:\n",
    "            print(\"Vector database creation failed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
